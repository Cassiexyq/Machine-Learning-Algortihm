## ML-note

1. 常见的数学问题

2. 机器学习算法
   * 决策树
   * 随机森林
   * 逻辑回归 线性回归
   * SVM
   * bagging boosting 
   * GBDT  XGboost
   * 聚类 Kmeans, kmeans++

3. 神经网络模型结构

4. 问题汇总
   * CNN、RNN、GAN 网络 解释
   * 图像处理算法有哪些，特征提取，滤波，几何
   * 图像分类(Inception)
   * 目标检测(RCNN YOLO CTPN STDN)
   * 图像增强（去雾，夜景图像增强）
   * 图像分割，图像迁移
   * pytorch tensorflow  框架
   * K Means， 回归，决策树 SVM，Boosting，PCA
   * 数据库  MySQL  MongoDB  Redis
   * 计算机操作系统
   * python  JAVA  C++， 爬虫
   * 文本词向量 LSTM  embedding
   * Linux

5. 其他常见问题
   * 正则化，L1 L2
   * SVM是什么时候用线性核 什么时候用高斯核
   * SVM和LR区别
   * SVM 为什么对缺失值敏感，对噪声敏感
   * 为什么boosting一般树很浅，bagging树很深
   * 奥卡姆剃刀法则：根据奥卡姆，如果同样效果那么越简单的模型泛化效果越好

6. 概率题

   <https://blog.csdn.net/bertdai/article/details/78070092>	

   <https://www.cnblogs.com/fanling999/p/6777335.html>

7. 面试题

   <https://note.youdao.com/ynoteshare1/index.html?id=421e6845b896bbb8acd2b8514c36c0ad&type=note#/>

8. 问题：

   * 如果说在图像分类上利用目标检测的RPN或者是别的SSD之类的对感兴趣区域重新卷积了一下，再进行分类，所以对这个分类效果有一定程度的提升，进入目标检测网络之前的卷积特征和进入之后又卷积了区域后的卷积特征的区别是啥？
   * 不同卷积后接入别的网络都有什么样的效果，在图像分类的哪个backbone是用到了哪一层
   * 贝叶斯基于先验概率还是后验概率，有标签还是无标签
   * 线性表达式？
   * crf,hmm, memm gmm
   * Logit 回归 最小化后验概率？
   * 信息增益：特征 x的信息使得类Y的信息不确定性减少的程度
   * fpn 的结构，为了解决什么样的问题
   * 输入图像大小，目标物体的大小，anchor大小的设置
   * focal loss解决什么问题，具体公式，参数有什么作用
   * c++ const的作用
   * ssd OHEM  正负样本为什么1：3
   * python list tuple的区别
   * 散列表，优势，如何实现查找复杂度o(1)
   * 奥卡姆剃刀原则 什么时候是必要的
   * 过拟合的解决办法 梯度爆炸的解决办法
   * 传统图像特征
   * adaboost在人脸检测上应用很好的原因
   * SVM adaboost的流程
   * relu 为什么可以防止梯度消失
   * 深度可分离卷积的作用
   * mobileNet三个版本的区别
   * inception 四个版本的区别
   * mask rcnn  focal loss
   * 目标检测哪里用到L1 loss
   * YOLO 的 anchor选择
   * Linux 怎么知道一个文件下的文件个数

     

